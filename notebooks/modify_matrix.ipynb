{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from srgnn_model import SRGNN_model\n",
    "from tagnn_model import TAGNN_model\n",
    "from srgnn_datasets import SRGNN_Map_Dataset, Augment_Matrix_Dataset, SRGNN_sampler, Clusters_Matrix_Dataset\n",
    "from utils import load_model, get_dataset\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_by_hand(model, dataloaders):\n",
    "    m=[]\n",
    "    for i, d in enumerate(dataloaders):\n",
    "        hit,mrr=[],[]\n",
    "        for batch in tqdm(d, total=ceil(normal_test_dataset.length/opt.batchSize)):\n",
    "            batch=[x.to('cuda') for x in batch]\n",
    "            sub_scores, targets=model.predict_step(batch)\n",
    "            targets=targets.flatten()\n",
    "            for score, target in zip(sub_scores, targets):\n",
    "                correct_pred=torch.isin(target - 1, score)\n",
    "                hit.append(correct_pred.cpu().numpy())\n",
    "                if not correct_pred:\n",
    "                    mrr.append(0)\n",
    "                else:\n",
    "                    mrr.append(1 / (torch.where(score == target - 1)[0][0] + 1).cpu().numpy())\n",
    "        m.append((i, np.average(hit),np.average(mrr)))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id='jxgwsuta'\n",
    "#run_id= 'run-20240614_112333-4o6dnpcx' # digineticax b4 vacation\n",
    "#run_id='run-20240404_162708-ekuo66ei' # diginetica OLD\n",
    "#run_id='run-20240614_153017-zgpiq2xg' # yoochoose1/4\n",
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20240805_152836-9qftnkuw',\n",
    "    'run-20240614_112333-4o6dnpcx', # before vacation\n",
    "  #  'run-20240614_110415-s1ibwx8z',\n",
    "  #  'run-20240614_103554-9oalum92',\n",
    "  #  'run-20240614_100940-1qzerry1',\n",
    "  #  'run-20240614_090951-1we03ydl',\n",
    "  #  'run-20240531_122335-i78k1rzu',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    print('Metrics on normal Adjacency matrix')\n",
    "    print(run_id)\n",
    "    trainer.test(model, normal_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tagnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, 32, shuffle=False, drop_last=False)\n",
    "                            )\n",
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/32),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for run_id in runs:\n",
    "run_id='run-20240627_124634-3sqmsb5q'\n",
    "model,opt=load_model_tagnn(run_id)\n",
    "print('Metrics on normal Adjacency matrix')\n",
    "print(run_id)\n",
    "trainer.test(model, normal_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20240627_183323-4ak5m39f',\n",
    "    'run-20240627_155659-9kgnghb3',\n",
    "]\n",
    "\n",
    "for run_id in runs:\n",
    "    model,opt=load_model_tagnn(run_id)\n",
    "    dataset=get_dataset(opt)\n",
    "    am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(dataset, 32, shuffle=False, drop_last=False)\n",
    "                         )\n",
    "    print(run_id)\n",
    "    print('Distnace Augmentation:', opt.augment_matrix,\n",
    "        'Clusters:', opt.augment_clusters,\n",
    "          'Categories:', opt.augment_categories,\n",
    "          'Noise std: ', opt.augment_std\n",
    "          )\n",
    "    trainer.test(model, {'augmented':am_test_dataloader, 'normal':normal_test_dataloader})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test multiple models, trained with different augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yoochoose  \n",
    "runs=[\n",
    "    'run-20240619_102057-3gibtayg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20240621_131456-not829vl',\n",
    "    'run-20240614_142621-t3g6tq0x',\n",
    "    'run-20240614_131608-ej263e5q',\n",
    "    'run-20240614_121256-eb9o86a0',\n",
    "    'run-20240614_115350-nowjww5i',\n",
    "    'run-20240614_125159-mqzvnmnm', # multistep\n",
    "    'run-20240607_124758-qm1wk8n1'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    '9kf534bm', \n",
    "    'nbhakjb7', # updated blur - +=(U<p)*N\n",
    "\n",
    "    'fmm07us9', # old blur - if u<p: +=N\n",
    "    'wtqp9kti',\n",
    "\n",
    "    'fbshwixh', # old, a bit bugged\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    dataset=get_dataset(opt)\n",
    "    am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                         )\n",
    "    print(run_id)\n",
    "    print('Distnace Augmentation:', opt.augment_matrix,\n",
    "        'Clusters:', opt.augment_clusters,\n",
    "          'Categories:', opt.augment_categories,\n",
    "          'Noise std: ', opt.augment_std,\n",
    "          'base model', opt.augment_old_run_id,\n",
    "          )\n",
    "    trainer.test(model, {'augmented':am_test_dataloader, 'normal':normal_test_dataloader})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    #dataset=get_dataset(opt)\n",
    "   # am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "     #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "      #                   )\n",
    "    print(run_id)\n",
    "    print('Distnace Augmentation:', opt.augment_matrix,\n",
    "        'Clusters:', opt.augment_clusters,\n",
    "          'Categories:', opt.augment_categories,\n",
    "          'Noise std: ', opt.augment_std,\n",
    "          'base model', opt.augment_old_run_id,\n",
    "          )\n",
    "    results[run_id]=get_metrics_by_hand(model, [normal_test_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(results).T.reset_index()\n",
    "res_df[['DataLoader_id','hit','mrr']]=pd.DataFrame(res_df[0].to_list(), columns=['DataLoader_id','hit','mrr'])\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df[['hit','mrr']].iloc[:2].mean(), res_df[['hit','mrr']].iloc[2:4].mean(), res_df[['hit','mrr']].iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models - from wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yoochoose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20240523_184137-2hmeyq20',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    dataset=get_dataset(opt)\n",
    "    am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                         )\n",
    "    print(run_id)\n",
    "    print('Clusters:', opt.augment_clusters,\n",
    "        'Normalization:', opt.augment_normalize,\n",
    "          'Distance clip:', opt.augment_clip,\n",
    "          'Raw distance:', opt.augment_raw,\n",
    "          'GNN steps', opt.step,\n",
    "          'l2 weight decay', opt.l2)\n",
    "    trainer.test(model, {'augmented':am_test_dataloader, 'normal':normal_test_dataloader})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## digenetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'fbshwixh',\n",
    "    'qjryadwd',\n",
    "    'run-20240503_221548-snlgztbm',\n",
    "    'run-20240503_180753-7exj1dpy',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    dataset=get_dataset(opt)\n",
    "    am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                         )\n",
    "    print(run_id)\n",
    "    print('Clusters:', opt.augment_clusters,\n",
    "        'Normalization:', opt.augment_normalize,\n",
    "          'Distance clip:', opt.augment_clip,\n",
    "          'Raw distance:', opt.augment_raw,\n",
    "          'GNN steps', opt.step,\n",
    "          'l2 weight decay', opt.l2)\n",
    "    trainer.test(model, {'augmented':am_test_dataloader, 'normal':normal_test_dataloader})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare best augmented and normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run_id='jxgwsuta' # diginetica\n",
    "#base_run_id='run-20240422_103727-ex2zwqx6' # yoochoose1/4\n",
    "base_model,opt=load_model(base_run_id)\n",
    "\n",
    "aug_run_id='8llxhkxm'\n",
    "aug_model,aug_opt=load_model(aug_run_id) # diginetica\n",
    "#aug_model,aug_opt=load_model('run-20240523_184137-2hmeyq20') # yoochoose1/4\n",
    "\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sessions, test_targets, test_sids=test_data[:3]\n",
    "test_session_ids=set(map(int, test_sids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_opt.augment_noise_p=0\n",
    "aug_opt.augment_p=1\n",
    "aug_dataset=get_dataset(aug_opt, test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=[]\n",
    "\n",
    "base_model.to('cuda')\n",
    "aug_model.to('cuda')\n",
    "for batch in tqdm(test_dataloader, total=test_dataset.length//opt.batchSize):\n",
    "    batch=[b.to('cuda') for b in batch]\n",
    "\n",
    "    base_sub_scores, targets=base_model.predict_step(batch)\n",
    "    aug_sub_scores, _=aug_model.predict_step(batch)\n",
    "    targets=targets.flatten()\n",
    "    for bscore, augscore, target in zip(base_sub_scores, aug_sub_scores, targets):\n",
    "        base_correct_pred=torch.isin(target - 1, bscore).cpu()\n",
    "        base_hit=(base_correct_pred)\n",
    "        if not base_correct_pred:\n",
    "            base_mrr=0\n",
    "        else:\n",
    "            base_mrr=(1 / (torch.where(bscore == target - 1)[0][0] + 1).cpu())\n",
    "\n",
    "        aug_correct_pred=torch.isin(target - 1, augscore).cpu()\n",
    "        aug_hit=(aug_correct_pred)\n",
    "        if not aug_correct_pred:\n",
    "            aug_mrr=0\n",
    "        else:\n",
    "            aug_mrr=(1 / (torch.where(augscore == target - 1)[0][0] + 1).cpu())\n",
    "        stats.append((base_mrr, base_hit, aug_mrr, aug_hit))\n",
    "\n",
    "base_model.to('cpu')\n",
    "aug_model.to('cpu')\n",
    "stats=np.array(stats)\n",
    "print('Base mrr:', 100*np.average(stats[:,0]),'Augmented mrr:', 100*np.average(stats[:,2]),\n",
    "      '\\nBase hit:', 100*np.average(stats[:,1]),'Augmented hit:', 100*np.average(stats[:,3]),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df=pd.DataFrame(stats, columns=['base_mrr', 'base_hit', 'aug_mrr','aug_hit'])\n",
    "stats_df['session_id']=test_sids\n",
    "stats_df['target_number']=test_targets\n",
    "stats_df['session_len']=list(map(lambda x: len(x), test_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df=pd.read_csv(f'../datasets/{opt.dataset}/items.csv').drop(columns=[ 'Unnamed: 0'])\n",
    "if aug_opt.augment_alg!='raw':\n",
    "    with open(f\"../datasets/diginetica/item_labels_{aug_opt.augment_alg}_{aug_opt.augment_nogmm}_{aug_opt.augment_gmm_init}_{aug_opt.gmm_covariance_type}_{aug_opt.gmm_tol}_{aug_opt.hiddenSize}_{base_run_id.split('-')[-1]}.txt\", 'rb') as file:\n",
    "        item_labels=pickle.load(file)\n",
    "    items_df['item_cluster']=items_df.item_number.map(lambda x: item_labels[x])\n",
    "else:\n",
    "    items_df['item_cluster']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aug_opt.augment_alg!='raw':\n",
    "    stats_df['clusters']=[ (set(items_df.loc[items_df.item_number.isin(ses)].item_cluster )) for ses in test_sessions]\n",
    "    stats_df['target_cluster']=stats_df.target_number.map(lambda x: item_labels[x])\n",
    "    stats_df['target_cluster_in_ses']=stats_df.apply(lambda r: r.target_cluster in r.clusters, axis=1)\n",
    "    stats_df['no_clusters']=stats_df.clusters.map(lambda x: len(x))\n",
    "stats_df['repetitions_in_session']=[len(ses)!=len(set(ses)) for ses in test_sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['target_category']=stats_df.target_number.map(lambda x: items_df.loc[items_df.item_number==x].category.item())\n",
    "stats_df['categories']=[ (set(items_df.loc[items_df.item_number.isin(ses)].category )) for ses in test_sessions]\n",
    "\n",
    "stats_df['target_category_in_ses']=stats_df.apply(lambda r: r.target_category in r.categories, axis=1)\n",
    "stats_df['no_categories']=stats_df.categories.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_df=pd.read_csv(f'../datasets/{opt.dataset}/test_sessions.csv').drop(columns=[ 'Unnamed: 0'])\n",
    "sess_df=sess_df.loc[sess_df.session_id.isin(test_session_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_df=pd.read_csv(f'../datasets/{opt.dataset}/clicks_df.csv').drop(columns='Unnamed: 0')\n",
    "clicks_df=clicks_df.loc[clicks_df.session_id.isin(test_session_ids)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df=stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "]\n",
    "base_df=stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "]\n",
    "equal_df=stats_df.loc[\n",
    "    (stats_df.base_mrr==stats_df.aug_mrr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_items_embedding(model, item_ids: torch.tensor):\n",
    "    return model.model.embedding(item_ids)\n",
    "base_items_embeddings=get_items_embedding(base_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n",
    "aug_items_embeddings=get_items_embedding(aug_model, torch.arange(items_df.item_number.nunique()+1, device=aug_model.device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aug_df),len(base_df),len(equal_df),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "    #(stats_df.base_hit<stats_df.aug_hit)\n",
    "    #&(~stats_df.target_cluster_in_ses)\n",
    "  #  &(stats_df.no_clusters>1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "    &(stats_df.base_hit==stats_df.aug_hit)\n",
    "    &(stats_df.base_hit)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "    &(stats_df.base_hit==stats_df.aug_hit)\n",
    "    &(stats_df.base_hit)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# sessions for hit base>aug', stats_df.loc[\n",
    "    (stats_df.base_hit>stats_df.aug_hit)\n",
    "].shape , '# sessions opposite',\n",
    "stats_df.loc[\n",
    "    (stats_df.base_hit<stats_df.aug_hit)\n",
    "].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=(sum(stats_df.base_hit>stats_df.aug_hit),\n",
    "sum(stats_df.base_hit==stats_df.aug_hit),\n",
    "sum(stats_df.base_hit<stats_df.aug_hit))\n",
    "plt.title(f'HIT comparison. Aug. better on {c-a} sessions')\n",
    "plt.bar([1,2, 3], height=[a,b,c],\n",
    "label=['base','equal','aug'],\n",
    "color=['C0','C1','C2'])\n",
    "plt.yticks(np.arange(0,max(a,b,c)+5000, 5000))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=(sum(stats_df.base_mrr>stats_df.aug_mrr),\n",
    "sum(stats_df.base_mrr==stats_df.aug_mrr),\n",
    "sum(stats_df.base_mrr<stats_df.aug_mrr))\n",
    "\n",
    "plt.title(f'MRR comparison. Aug. better on {c-a} sessions')\n",
    "plt.bar([1,2, 3], height=[a,b,c], \n",
    "label=['base','equal','aug'],\n",
    "color=['C0','C1','C2'])\n",
    "plt.yticks(np.arange(0,max(a,b,c), 5000))\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1,2], height=[\n",
    "    sum(stats_df.repetitions_in_session),\n",
    "    sum(~stats_df.repetitions_in_session)\n",
    "], label=['repetitions in sesssion', 'unique items in session'],\n",
    "color=['C0', 'C1'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(stats_df.base_mrr[stats_df.base_mrr>0], bins=20, label='base')\n",
    "plt.hist(stats_df.aug_mrr[stats_df.aug_mrr>0], bins=20, label='augmented', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title('MRR distribution (without non-hits)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1,2,3,4,5,6], height=[\n",
    "    sum(aug_df.target_cluster_in_ses),\n",
    "    sum(~aug_df.target_cluster_in_ses),\n",
    "    sum(base_df.target_cluster_in_ses),\n",
    "    sum(~base_df.target_cluster_in_ses),\n",
    "    sum(equal_df.target_cluster_in_ses),\n",
    "    sum(~equal_df.target_cluster_in_ses)\n",
    "], label=['AUG target cluster in session', 'opposite', \n",
    "          'BASE target cluster in session', 'opposite', \n",
    "          'EQUAL target cluster in session', 'opposite', ],\n",
    "color=['green', 'blue', 'lightgreen', 'lightblue', 'darkgreen', 'darkblue'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1,2,3,4,5,6], height=[\n",
    "    sum(aug_df.target_cluster_in_ses),\n",
    "    sum(~aug_df.target_cluster_in_ses),\n",
    "    sum(base_df.target_cluster_in_ses),\n",
    "    sum(~base_df.target_cluster_in_ses),\n",
    "    sum(equal_df.target_cluster_in_ses),\n",
    "    sum(~equal_df.target_cluster_in_ses)\n",
    "], label=['AUG target cluster in session', 'opposite', \n",
    "          'BASE target cluster in session', 'opposite', \n",
    "          'EQUAL target cluster in session', 'opposite', ],\n",
    "color=['green', 'blue', 'lightgreen', 'lightblue', 'darkgreen', 'darkblue'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### repetitions, clusters & session len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df=stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "]\n",
    "base_df=stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('no. clusters in session')\n",
    "plt.hist(aug_df.no_clusters.values, bins=np.arange(stop=aug_df.no_clusters.nunique(), start=1), density=True, label='aug')\n",
    "plt.hist(base_df.no_clusters.values, bins=np.arange(stop=base_df.no_clusters.nunique(), start=1), alpha=0.5, density=True, label='base')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('session length')\n",
    "plt.hist(aug_df.session_len.values, bins=np.arange(stop=aug_df.session_len.nunique(), start=1), density=True, label='aug')\n",
    "plt.hist(base_df.session_len.values, bins=np.arange(stop=base_df.session_len.nunique(), start=1), alpha=0.5, density=True, label='base')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d=(sum(aug_df.repetitions_in_session),\n",
    "    sum(~aug_df.repetitions_in_session),\n",
    "    sum(base_df.repetitions_in_session),\n",
    "    sum(~base_df.repetitions_in_session))\n",
    "\n",
    "plt.bar([1,2,3,4], height=[\n",
    "    sum(aug_df.repetitions_in_session),\n",
    "    sum(~aug_df.repetitions_in_session),\n",
    "    sum(base_df.repetitions_in_session),\n",
    "    sum(~base_df.repetitions_in_session)\n",
    "], label=['AUG repetitions in sesssion', 'AUG unique items in session', 'BASE repetitions in sesssion', 'BASE unique items in session'],\n",
    "color=['green', 'blue', 'lightgreen', 'lightblue'])\n",
    "plt.legend()\n",
    "\n",
    "plt.title(f'AUG rep%: {100*a/(a+b):.2f}; BASE rep%: {100*c/(c+d):.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### due to normalization, diff should be only on session with repetition. CHECK it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not really. Adjacency matrix indeed is different only then, but models weights differ all the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_df=stats_df.loc[stats_df.repetitions_in_session]\n",
    "print('session with repetition #', rep_df.shape[0], ', Base hits:', sum(rep_df.base_hit), ', Aug hits:', sum(rep_df.aug_hit),\n",
    "      '\\n Percentage of different MRR results:', np.round(100*sum(rep_df.base_mrr!=rep_df.aug_mrr)/rep_df.shape[0], 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notrep_df=stats_df.loc[~stats_df.repetitions_in_session]\n",
    "print('Sessions without repetition! #', notrep_df.shape[0], ', Base hits:', sum(notrep_df.base_hit), ', Aug hits:', sum(notrep_df.aug_hit),\n",
    "      '\\n Percentage of different MRR esults:', np.round(100*sum(notrep_df.base_mrr!=notrep_df.aug_mrr)/notrep_df.shape[0], 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage gain in sessions with repetitions, regarding better MRR ')\n",
    "100*((rep_df.aug_mrr>rep_df.base_mrr).sum()-(rep_df.aug_mrr<rep_df.base_mrr).sum())/len(rep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df=stats_df.merge(items_df[['pricelog2','category','frequency','item_number']].rename(columns={'item_number':'target_number'}), \n",
    "             on='target_number',\n",
    "             how='left')\n",
    "stats_df['avg_sesssion_freq']=list(map(lambda ses: np.average([items_df.loc[items_df.item_number==x].frequency.item() for x in ses]) ,test_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df=stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "]\n",
    "base_df=stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "]\n",
    "equal_df=stats_df.loc[\n",
    "    (stats_df.base_mrr==stats_df.aug_mrr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('frequency of target')\n",
    "plt.hist(aug_df.frequency.values, bins=np.arange(400, step=20), density=True, label='aug')\n",
    "plt.hist(base_df.frequency.values, bins=np.arange(400, step=20), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.frequency.values, bins=np.arange(400, step=20), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('frequency<100 of target')\n",
    "plt.hist(aug_df.frequency.values, bins=np.arange(100, step=2), density=True, label='aug')\n",
    "plt.hist(base_df.frequency.values, bins=np.arange(100, step=2), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.frequency.values, bins=np.arange(100, step=2), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('frequency of target')\n",
    "plt.hist(aug_df.frequency.values, bins=np.arange(400, step=20), density=True, label='aug')\n",
    "plt.hist(base_df.frequency.values, bins=np.arange(400, step=20), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.frequency.values, bins=np.arange(400, step=20), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('frequency<100 of target')\n",
    "plt.hist(aug_df.frequency.values, bins=np.arange(100, step=2), density=True, label='aug')\n",
    "plt.hist(base_df.frequency.values, bins=np.arange(100, step=2), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.frequency.values, bins=np.arange(100, step=2), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('avg session frequency')\n",
    "plt.hist(aug_df.avg_sesssion_freq.values, bins=np.arange(400, step=20), density=True, label='aug')\n",
    "plt.hist(base_df.avg_sesssion_freq.values, bins=np.arange(400, step=20), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.avg_sesssion_freq.values, bins=np.arange(400, step=20), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('avg session frequency<100')\n",
    "plt.hist(aug_df.avg_sesssion_freq.values, bins=np.arange(stop=100, start=5, step=2), density=True, label='aug')\n",
    "plt.hist(base_df.avg_sesssion_freq.values, bins=np.arange(stop=100, start=5, step=2), alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.avg_sesssion_freq.values, bins=np.arange(stop=100, start=5, step=2), alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('price of target')\n",
    "plt.hist(aug_df.pricelog2.values, bins=10, density=True, label='aug')\n",
    "plt.hist(base_df.pricelog2.values, bins=10, alpha=0.6, density=True, label='base')\n",
    "plt.hist(equal_df.pricelog2.values, bins=10, alpha=0.3, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_emb_center=np.average(base_items_embeddings, axis=0)\n",
    "aug_emb_center=np.average(aug_items_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['base_sesssion_emb']=(list(map(lambda ses: np.average(base_items_embeddings[ses], axis=0) ,test_sessions)))\n",
    "stats_df['aug_sesssion_emb']=list(map(lambda ses: np.average(aug_items_embeddings[ses], axis=0) ,test_sessions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df=stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "]\n",
    "base_df=stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "]\n",
    "equal_df=stats_df.loc[\n",
    "    (stats_df.base_mrr==stats_df.aug_mrr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('Target distance from BASE embedding_space center')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[aug_df.target_number.values]-base_emb_center, axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[base_df.target_number.values]-base_emb_center, axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[equal_df.target_number.values]-base_emb_center, axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Target distance from AUGMENTED embedding_space center')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[aug_df.target_number.values]-aug_emb_center, axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[base_df.target_number.values]-aug_emb_center, axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[equal_df.target_number.values]-aug_emb_center, axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OLDDDDDDDDDDDDD\n",
    "plt.title('Target distance from BASE embedding_space center')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[aug_df.target_number.values]-base_emb_center, axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[base_df.target_number.values]-base_emb_center, axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[equal_df.target_number.values]-base_emb_center, axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Target distance from AUGMENTED embedding_space center')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[aug_df.target_number.values]-aug_emb_center, axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[base_df.target_number.values]-aug_emb_center, axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[equal_df.target_number.values]-aug_emb_center, axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('Target distance from BASE session center')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[aug_df.target_number.values]-np.asarray([x for x in aug_df.base_sesssion_emb.values]), \n",
    "                        axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[base_df.target_number.values]-np.asarray([x for x in base_df.base_sesssion_emb.values]), axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[equal_df.target_number.values]-np.asarray([x for x in equal_df.base_sesssion_emb.values]), axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Target distance from AUGMENTED session center')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[aug_df.target_number.values]-np.asarray([x for x in aug_df.aug_sesssion_emb.values]), axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[base_df.target_number.values]-np.asarray([x for x in base_df.aug_sesssion_emb.values]), axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[equal_df.target_number.values]-np.asarray([x for x in equal_df.aug_sesssion_emb.values]), axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### OLDDDDDDDDDDDDDDDDDDd\n",
    "plt.title('Target distance from BASE session center')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[aug_df.target_number.values]-np.asarray([x for x in aug_df.base_sesssion_emb.values]), \n",
    "                        axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[base_df.target_number.values]-np.asarray([x for x in base_df.base_sesssion_emb.values]), axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(base_items_embeddings[equal_df.target_number.values]-np.asarray([x for x in equal_df.base_sesssion_emb.values]), axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Target distance from AUGMENTED session center')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[aug_df.target_number.values]-np.asarray([x for x in aug_df.aug_sesssion_emb.values]), axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[base_df.target_number.values]-np.asarray([x for x in base_df.aug_sesssion_emb.values]), axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(aug_items_embeddings[equal_df.target_number.values]-np.asarray([x for x in equal_df.aug_sesssion_emb.values]), axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### same but on clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../datasets/{opt.dataset}/cluster_centers_16_{opt.hiddenSize}_{base_run_id.split('-')[-1]}.txt\", \n",
    "            'rb') as f:\n",
    "      cluster_centers=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['cluster_sesssion_emb']=(list(map(lambda ses: np.average(cluster_centers[item_labels[ses]], axis=0) ,test_sessions)))\n",
    "aug_df=stats_df.loc[\n",
    "    (stats_df.base_mrr<stats_df.aug_mrr)\n",
    "]\n",
    "base_df=stats_df.loc[\n",
    "    (stats_df.base_mrr>stats_df.aug_mrr)\n",
    "]\n",
    "equal_df=stats_df.loc[\n",
    "    (stats_df.base_mrr==stats_df.aug_mrr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('TargetCluster distance from Session avg Cluster center')\n",
    "plt.hist(np.linalg.norm(cluster_centers[item_labels[aug_df.target_number.values]]-np.asarray([x for x in aug_df.cluster_sesssion_emb.values]), \n",
    "                        axis=1), \n",
    "         bins=100, density=True, label='aug')\n",
    "\n",
    "plt.hist(np.linalg.norm(cluster_centers[item_labels[base_df.target_number.values]]-np.asarray([x for x in base_df.cluster_sesssion_emb.values]), axis=1),  \n",
    "         bins=100, alpha=0.6, density=True, label='base')\n",
    "plt.hist(np.linalg.norm(cluster_centers[item_labels[equal_df.target_number.values]]-np.asarray([x for x in equal_df.cluster_sesssion_emb.values]), axis=1), \n",
    "         bins=100, alpha=0.5, density=True, label='equal')\n",
    "plt.legend()\n",
    "plt.ylim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot & compare embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne=TSNE(2, init='random', early_exaggeration=32)\n",
    "tsne_items_embeddings=tsne.fit_transform(aug_items_embeddings)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for label in np.unique(item_labels):\n",
    "    label_embedding=tsne_items_embeddings[item_labels==label]\n",
    "    fig.add_trace(go.Scatter(x=label_embedding[:,0], y=label_embedding[:,1], name=str(label), mode='markers'))\n",
    "\n",
    "fig.update_layout(title='TSNE reduced items embeddings from model with augmented adjacency matrix',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/items_AUGMATRIX_tsne{tsne.init}_{opt.dataset}_{opt.hiddenSize}_{base_run_id.split(\"-\")[-1]}_{aug_run_id.split(\"-\")[-1]}.html')\n",
    "del fig\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne=TSNE(2, init='random', early_exaggeration=32)\n",
    "tsne_items_embeddings=tsne.fit_transform(base_items_embeddings)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for label in np.unique(item_labels):\n",
    "    label_embedding=tsne_items_embeddings[item_labels==label]\n",
    "    fig.add_trace(go.Scatter(x=label_embedding[:,0], y=label_embedding[:,1], name=str(label), mode='markers'))\n",
    "\n",
    "fig.update_layout(title='TSNE reduced items embeddings from model with augmented adjacency matrix',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/items_BASE_tsne{tsne.init}_{opt.dataset}_{opt.hiddenSize}_{base_run_id.split(\"-\")[-1]}_{aug_run_id.split(\"-\")[-1]}.html')\n",
    "del fig\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('no. categories in session')\n",
    "plt.hist(aug_df.no_categories.values, bins=np.arange(stop=stats_df.no_categories.nunique(), start=1), density=True, label='aug')\n",
    "plt.hist(base_df.no_categories.values, bins=np.arange(stop=stats_df.no_categories.nunique(), start=1), alpha=0.5, density=True, label='base')\n",
    "plt.hist(equal_df.no_categories.values, bins=np.arange(stop=stats_df.no_categories.nunique(), start=1), alpha=0.5, density=True, label='base')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([1,2,3,4], height=[\n",
    "    sum(aug_df.target_category_in_ses),\n",
    "    sum(~aug_df.target_category_in_ses),\n",
    "    sum(base_df.target_category_in_ses),\n",
    "    sum(~base_df.target_category_in_ses)\n",
    "], label=['AUG target cat in sesssion', 'AUG opposite', 'BASE target cat in sesssion', 'BASE opposite'],\n",
    "color=['green', 'blue', 'lightgreen', 'lightblue'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne=TSNE(2, init='random', early_exaggeration=32, verbose=1)\n",
    "base_tsne_items_embeddings=tsne.fit_transform(base_items_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne=TSNE(2, init='random', early_exaggeration=32, verbose=1)\n",
    "aug_tsne_items_embeddings=tsne.fit_transform(aug_items_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'base', np.linalg.norm(base_items_embeddings.max(axis=0)-base_items_embeddings.min(axis=0)), 'aug', np.linalg.norm(aug_items_embeddings.max(axis=0)-aug_items_embeddings.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "colors=px.colors.qualitative.Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_opt.augment_noise_p=0.5\n",
    "aug_opt.augment_p=1\n",
    "aug_dataset=get_dataset(aug_opt, test_data, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hit5=stats_df.base_mrr>=0.2\n",
    "aug_hit5=stats_df.aug_mrr>=0.2\n",
    "100*np.average(base_hit5), 100*np.average(aug_hit5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.random.choice(rep_df.loc[(rep_df.aug_mrr>rep_df.base_mrr)\n",
    "           &(rep_df.no_categories>1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx=12906\n",
    "idx=27278\n",
    "#idx=34098\n",
    "seqence=test_sessions[idx]\n",
    "target=test_targets[idx]\n",
    "r=rep_df.loc[idx]\n",
    "idx, r.base_mrr, r.aug_mrr, seqence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[[idx]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(np.round(aug_dataset[[idx,idx]][1], decimals=3)[0])\n",
    "s=''\n",
    "for i in a:\n",
    "    s+='&'+'&'.join(['\\\\textbf{'+str(j)+'}' if j>0.2 else (str(j) if j!=int(j) else str(int(j))) for j in i[len(i)//2:] ])+'\\\\\\\\ \\\\hline'+'\\n'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(np.round(test_dataset[[idx, idx]][1], decimals=3)[0])\n",
    "s=''\n",
    "for k, i in enumerate(a):\n",
    "    s+=f'{k}&'+'&'.join(['\\\\textbf{'+str(j)+'}' if j>0.2 else (str(j) if j!=int(j) else str(int(j))) for j in i[len(i)//2:] ])+'\\\\\\\\ \\\\hline'+'\\n'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(1, r.session_len):\n",
    "    print(f'{i}->{i+1}',\n",
    "          'base ',\n",
    "          np.linalg.norm(base_items_embeddings[seqence[i]]-base_items_embeddings[seqence[i-1]]),\n",
    "          'aug ',\n",
    "          np.linalg.norm(aug_items_embeddings[seqence[i]]-aug_items_embeddings[seqence[i-1]]),\n",
    "          )\n",
    "print('last->target',\n",
    "        'base ',\n",
    "      np.linalg.norm(base_items_embeddings[seqence[-1]]-base_items_embeddings[target]),\n",
    "        'aug ',\n",
    "      np.linalg.norm(aug_items_embeddings[seqence[-1]]-aug_items_embeddings[target]),\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.loc[items_df.item_number.isin(seqence+[target])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i, item in enumerate(seqence):#[np.unique(item_labels, return_counts=True)[1]>len(item_labels)/ngmm]:\n",
    "    sequence_embedding=base_tsne_items_embeddings[item] \n",
    "    fig.add_trace(go.Scatter(x=[sequence_embedding[0]], y=[sequence_embedding[1]], \n",
    "                             name=f'item_{i}', mode='markers', \n",
    "                             marker=dict(size=20,\n",
    "                                       #  color=colors[item_labels[item]],\n",
    "                                        line=dict(width=2,\n",
    "                                        color='DarkSlateGrey'))))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x=[base_tsne_items_embeddings[target][0]], y=[base_tsne_items_embeddings[target][1]], \n",
    "                             name=f'target', mode='markers', \n",
    "                            marker=dict(size=30,\n",
    "                                      #color=colors[item_labels[target]],\n",
    "                                        line=dict(width=2,\n",
    "                                        color='DarkSlateGrey'))))\n",
    "\n",
    "sequence_embedding=base_tsne_items_embeddings[seqence]\n",
    "fig.add_trace(go.Scatter(x=sequence_embedding[:, 0], y=sequence_embedding[:, 1], \n",
    "                             name='session', mode='markers+lines', \n",
    "                             marker=dict(symbol=\"arrow\",\n",
    "                                        size=15,\n",
    "                                        angleref=\"previous\",\n",
    "                                        color='Black')\n",
    "                                        ))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[sequence_embedding[-1, 0], base_tsne_items_embeddings[target][0]],\n",
    "                          y=[sequence_embedding[-1, 1], base_tsne_items_embeddings[target][1]], \n",
    "                             name='prediciton', mode='markers+lines', \n",
    "                             marker=dict(symbol=\"arrow\",\n",
    "                                        size=15,\n",
    "                                        angleref=\"previous\",\n",
    "                                        color='Red')\n",
    "                                        ))\n",
    "    \n",
    "fig.update_layout(title='',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/sequence_BASE_tsne_{tsne.init}_{opt.dataset}_{aug_opt.augment_alg}_{base_run_id.split(\"-\")[-1]}.html')\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for i, item in enumerate(seqence):#[np.unique(item_labels, return_counts=True)[1]>len(item_labels)/ngmm]:\n",
    "    sequence_embedding=aug_tsne_items_embeddings[item] \n",
    "    fig.add_trace(go.Scatter(x=[sequence_embedding[0]], y=[sequence_embedding[1]], \n",
    "                             name=f'item_{i}', mode='markers', \n",
    "                             marker=dict(size=20,\n",
    "                                       #  color=colors[item_labels[item]],\n",
    "                                        line=dict(width=2,\n",
    "                                        color='DarkSlateGrey'))))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x=[aug_tsne_items_embeddings[target][0]], y=[aug_tsne_items_embeddings[target][1]], \n",
    "                             name=f'target', mode='markers', \n",
    "                            marker=dict(size=30,\n",
    "                                      #color=colors[item_labels[target]],\n",
    "                                        line=dict(width=2,\n",
    "                                        color='DarkSlateGrey'))))\n",
    "\n",
    "sequence_embedding=aug_tsne_items_embeddings[seqence]\n",
    "fig.add_trace(go.Scatter(x=sequence_embedding[:, 0], y=sequence_embedding[:, 1], \n",
    "                             name='session', mode='markers+lines', \n",
    "                             marker=dict(symbol=\"arrow\",\n",
    "                                        size=15,\n",
    "                                        angleref=\"previous\",\n",
    "                                        color='Black')\n",
    "                                        ))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[sequence_embedding[-1, 0], aug_tsne_items_embeddings[target][0]],\n",
    "                          y=[sequence_embedding[-1, 1], aug_tsne_items_embeddings[target][1]], \n",
    "                             name='prediciton', mode='markers+lines', \n",
    "                             marker=dict(symbol=\"arrow\",\n",
    "                                        size=15,\n",
    "                                        angleref=\"previous\",\n",
    "                                        color='Red')\n",
    "                                        ))\n",
    "    \n",
    "fig.update_layout(title='',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/sequence_AUG_tsne_{tsne.init}_{opt.dataset}_{aug_opt.augment_alg}_{aug_run_id.split(\"-\")[-1]}.html')\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_df.loc[sess_df.session_id==133163]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare recommendations between all approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run_id='jxgwsuta' # diginetica\n",
    "#base_run_id='run-20240422_103727-ex2zwqx6' # yoochoose1/4\n",
    "base_model,opt=load_model(base_run_id)\n",
    "\n",
    "i2i_run_id='8llxhkxm'\n",
    "i2i_model,i2i_opt=load_model(i2i_run_id) # diginetica\n",
    "\n",
    "cat_run_id='op22qkq4'\n",
    "cat_model,cat_opt=load_model(cat_run_id) # diginetica\n",
    "\n",
    "gmm_run_id='7jkmaij6'\n",
    "gmm_model,gmm_opt=load_model(gmm_run_id) # diginetica\n",
    "\n",
    "kmeans_run_id='6i71w436'\n",
    "kmeans_model,kmeans_opt=load_model(kmeans_run_id) # diginetica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_items_embeddings=get_items_embedding(base_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n",
    "i2i_items_embeddings=get_items_embedding(i2i_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n",
    "cat_items_embeddings=get_items_embedding(cat_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n",
    "gmm_items_embeddings=get_items_embedding(gmm_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n",
    "kmeans_items_embeddings=get_items_embedding(kmeans_model, torch.arange(items_df.item_number.nunique()+1, device=base_model.device)).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch=[torch.tensor(a) for a in test_dataset[[idx,idx]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.to('cpu')\n",
    "i2i_model.to('cpu')\n",
    "cat_model.to('cpu')\n",
    "gmm_model.to('cpu')\n",
    "kmeans_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preds=base_model.predict_step(batch)[0][0].numpy()+1\n",
    "i2i_preds=i2i_model.predict_step(batch)[0][0].numpy()+1\n",
    "cat_preds=cat_model.predict_step(batch)[0][0].numpy()+1\n",
    "gmm_preds=gmm_model.predict_step(batch)[0][0].numpy()+1\n",
    "kmeans_preds=kmeans_model.predict_step(batch)[0][0].numpy()+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_preds,i2i_preds,cat_preds, gmm_preds, kmeans_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(5, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[base_tsne_items_embeddings[target][0]], y=[base_tsne_items_embeddings[target][1]], \n",
    "                             name=f'target', mode='markers', \n",
    "                            marker=dict(size=30,\n",
    "                                      #color=colors[item_labels[target]],\n",
    "                                        line=dict(width=2,\n",
    "                                        color='DarkSlateGrey'))))\n",
    "\n",
    "k=10\n",
    "for preds, name in zip([base_preds, i2i_preds, cat_preds, gmm_preds, kmeans_preds], ['base','i2i','categories','GMM','KMeans']):\n",
    "  embedding=base_tsne_items_embeddings[preds[:k]] \n",
    "  fig.add_trace(go.Scatter(x=embedding[:,0], y=embedding[:,1], \n",
    "                              name=name, mode='markers', \n",
    "                              marker=dict(size=np.linspace(20,10,k),\n",
    "                                          opacity=0.5,\n",
    "                                        #  color=colors[item_labels[item]],\n",
    "                                          line=dict(width=2,\n",
    "                                          color='DarkSlateGrey'))))\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "fig.update_layout(title='',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/recommendations_tsne_{tsne.init}_{opt.dataset}_{aug_opt.augment_alg}_{aug_run_id.split(\"-\")[-1]}.html')\n",
    "del fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare their distance to target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_emb=base_items_embeddings[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict={}\n",
    "k=20\n",
    "for preds, name in zip([base_preds, i2i_preds, cat_preds, gmm_preds, kmeans_preds], ['base','i2i','categories','GMM','KMeans']):\n",
    "\n",
    "    dist_dict[name]=[np.linalg.norm(target_emb - base_items_embeddings[x]) for x in preds[:k] if x!=target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dist_dict.items():\n",
    "    print(f'{k: <11} & ',  ' & '.join([str(x) for x in np.round(np.cumsum(v), decimals=3)]), '\\\\\\\\ \\\\hline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
