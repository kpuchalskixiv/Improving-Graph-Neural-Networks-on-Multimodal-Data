{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from srgnn_model import SRGNN_model\n",
    "from srgnn_datasets import SRGNN_Map_Dataset, SRGNN_sampler\n",
    "from utils import fake_parser\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from math import ceil\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_run_id='4dm99qnd'\n",
    "\n",
    "#finetuned_run_id='run-20240302_233004-xh5dmcet'\n",
    "#global_run_id=finetuned_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt=load_model(global_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./GMMs/gmm_val_32_k-means++_{opt.hiddenSize}_{opt.dataset}_{opt.augment_matrix}_{global_run_id}.gmm', 'rb') as gmm_file:\n",
    "    gm=pickle.load(gmm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "test_dataloader=DataLoader(test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(test_dataset, opt.batchSize, shuffle=False, drop_last=False),\n",
    "                             drop_last=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate each cluster model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_emb=[]\n",
    "hit,mrr=[],[]\n",
    "\n",
    "model.to('cuda')\n",
    "for batch in tqdm(test_dataloader, total=test_dataset.length//opt.batchSize):\n",
    "    batch=[b.to('cuda') for b in batch]\n",
    "    session_emb.append(model.get_session_embeddings(batch).cpu().detach().numpy())\n",
    "\n",
    "    sub_scores, targets=model.predict_step(batch)\n",
    "    targets=targets.flatten()\n",
    "    for score, target in zip(sub_scores, targets):\n",
    "        correct_pred=torch.isin(target - 1, score).cpu()\n",
    "        hit.append(correct_pred)\n",
    "        if not correct_pred:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (torch.where(score == target - 1)[0][0] + 1).cpu())\n",
    "\n",
    "model.to('cpu')\n",
    "hit=np.array(hit)\n",
    "mrr=np.array(mrr)\n",
    "session_emb=np.concatenate(session_emb)\n",
    "print('hit ', 100*np.average(hit), 'mrr ', 100*np.average(mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_labels=[]\n",
    "for i in tqdm(range(ceil(session_emb.shape[0]/opt.batchSize))):\n",
    "    session_labels.append(gm.predict(session_emb[i*opt.batchSize: (i+1)*opt.batchSize]))\n",
    "session_labels=np.concatenate(session_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "tsne=TSNE(2)\n",
    "tsne_session_embeddings=tsne.fit_transform(session_emb)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for label in np.unique(session_labels):\n",
    "    label_embedding=tsne_session_embeddings[session_labels==label]\n",
    "    fig.add_trace(go.Scatter(x=label_embedding[:,0], y=label_embedding[:,1], name=str(label), mode='markers'))\n",
    "\n",
    "fig.update_layout(title='TSNE reduced session embeddings with GM',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/test_sessions_ONVAL_{gm.n_components}_{opt.dataset}_{opt.hiddenSize}_{global_run_id.split(\"-\")[-1]}.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df=pd.read_csv('./wandb_export_raw_all.csv')\n",
    "runs_df['cluster']=runs_df.Name.map(lambda x: int(x.split('_')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=[]\n",
    "cluster_results.append(\n",
    "{'cluster':-1, \n",
    " 'test_loss': np.nan,\n",
    " 'test_hit': np.average(hit),\n",
    " 'test_mrr': np.average(mrr)})\n",
    "\n",
    "for c in tqdm(range(gm.n_components)):\n",
    "    clear_output(wait=True)\n",
    "    idxs=np.arange(len(test_data[0]))[session_labels==c]\n",
    "\n",
    "    cluster_sess=[test_data[0][i] for i in idxs]\n",
    "    cluster_targets=[test_data[1][i] for i in idxs]\n",
    "    cluster_data=(cluster_sess,cluster_targets)\n",
    "    cluster_dataset=SRGNN_Map_Dataset(cluster_data, shuffle=False)\n",
    "    cluster_dataloader=DataLoader(cluster_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(cluster_dataset, opt.batchSize, shuffle=False, drop_last=False),\n",
    "                             drop_last=False\n",
    "                            )\n",
    "    run_id=runs_df.loc[runs_df.cluster==c].ID.item()\n",
    "    cluster_model=SRGNN_model.load_from_checkpoint(f\"./GNN_master/{run_id}/checkpoints/\"+\n",
    "                                       os.listdir(f\"./GNN_master/{run_id}/checkpoints/\")[0], opt=opt)\n",
    "    \n",
    "    trainer=pl.Trainer(limit_test_batches=ceil(cluster_dataset.length/opt.batchSize),limit_predict_batches=ceil(cluster_dataset.length/opt.batchSize))\n",
    "    metrics=trainer.test(cluster_model, cluster_dataloader)[0]#only one dataloader\n",
    "    metrics['cluster']=c\n",
    "    metrics['global_model_hit']=100*np.average(hit[idxs])\n",
    "    metrics['global_model_mrr']=100*np.average(mrr[idxs])\n",
    "    cluster_results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=pd.DataFrame(cluster_results)\n",
    "cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cluster_results.test_hit>cluster_results.global_model_hit).any(), (cluster_results.test_mrr>cluster_results.global_model_mrr).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.iloc[np.arange(cluster_results.shape[0])[cluster_results.test_mrr>cluster_results.global_model_mrr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.loc[cluster_results.global_model_hit<100*np.average(hit)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_session_emb=[]\n",
    "full_sessions=[]\n",
    "for batch in tqdm(test_dataloader, total=test_dataset.length//opt.batchSize):\n",
    "    # use only original sessions\n",
    "    a=batch[3][0]\n",
    "    a=torch.vstack([torch.zeros(a.shape[1]), a])\n",
    "    idxs=torch.diff(a, dim=0).sum(axis=1)\n",
    "    for i in range(len(batch)):\n",
    "        batch[i]=batch[i][:,idxs>0]\n",
    "    #print(batch[0].shape)\n",
    "    #break\n",
    "    full_sessions.append(batch)\n",
    "    full_session_emb.append(model.get_session_embeddings(batch).detach().numpy())\n",
    "full_session_emb=np.concatenate(full_session_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_session_labels=gm.predict(full_session_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_session_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hit,mrr=[],[]\n",
    "for batch in tqdm(full_sessions):\n",
    "    sub_scores, targets=model.predict_step(batch)\n",
    "    targets=targets.flatten()\n",
    "    for score, target in zip(sub_scores, targets):\n",
    "        correct_pred=torch.isin(target - 1, score)\n",
    "        hit.append(correct_pred)\n",
    "        if not correct_pred:\n",
    "            mrr.append(0)\n",
    "        else:\n",
    "            mrr.append(1 / (torch.where(score == target - 1)[0][0] + 1))\n",
    "hit=np.array(hit)\n",
    "mrr=np.array(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sess_results=[]\n",
    "full_sess_results.append(\n",
    "{'cluster':-1, \n",
    " 'global_model_hit': np.average(hit),\n",
    " 'global_model_mrr': np.average(mrr)})\n",
    "\n",
    "for c in tqdm(range(gm.n_components)):\n",
    "    clear_output(wait=True)\n",
    "    idxs=full_session_labels==c\n",
    "\n",
    "    run_id=runs_df.loc[runs_df.cluster==c].ID.item()\n",
    "    cluster_model=SRGNN_model.load_from_checkpoint(f\"./GNN_master/{run_id}/checkpoints/\"+\n",
    "                                       os.listdir(f\"./GNN_master/{run_id}/checkpoints/\")[0], opt=opt)\n",
    "    cluster_model.to('cpu')\n",
    "    \n",
    "    chit,cmrr=[],[]\n",
    "    counter=0\n",
    "    prev_batch=None\n",
    "    for batch in (full_sessions):\n",
    "        batch_idxs=idxs[counter:counter+batch[4].shape[-1]]\n",
    "        counter+=batch[4].shape[-1]\n",
    "\n",
    "        batch=[b[:, batch_idxs] for b in batch]\n",
    "        \n",
    "\n",
    "        sub_scores, targets=cluster_model.predict_step(batch)\n",
    "        targets=targets.flatten()\n",
    "        for score, target in zip(sub_scores, targets):\n",
    "            correct_pred=torch.isin(target - 1, score)\n",
    "            chit.append(correct_pred)\n",
    "            if not correct_pred:\n",
    "                cmrr.append(0)\n",
    "            else:\n",
    "                cmrr.append(1 / (torch.where(score == target - 1)[0][0] + 1))\n",
    "\n",
    "    metrics={}\n",
    "    metrics['cluster']=c\n",
    "    metrics['model_hit']=100*np.average(chit)\n",
    "    metrics['model_mrr']=100*np.average(cmrr)\n",
    "    metrics['global_model_hit']=100*np.average(hit[idxs])\n",
    "    metrics['global_model_mrr']=100*np.average(mrr[idxs])\n",
    "    full_sess_results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sess_results=pd.DataFrame(full_sess_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sess_results.iloc[(full_sess_results.model_mrr>full_sess_results.global_model_mrr).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sess_results.iloc[(full_sess_results.model_hit>full_sess_results.global_model_hit).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lenght_distribution(sess_lens, lim=8):\n",
    "    lens, sizes=np.unique(sess_lens, return_counts=True)\n",
    "    lim=min(lim, len(lens)-1)\n",
    "    sizes[lim-1]=np.sum(sizes[lim-1:])\n",
    "    sizes=sizes[:lim]\n",
    "    lens=lens[:lim]\n",
    "    sizes=sizes/sum(sizes)\n",
    "    return lens, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_ratio_per_len(lim=10):\n",
    "    hit_ratio=[]\n",
    "    for l in range(1,lim+1):\n",
    "        if l==lim:\n",
    "            lidxs=session_len>=l\n",
    "        else:\n",
    "            lidxs=session_len==l\n",
    "        hit_ratio.append(np.average(hit[lidxs]))\n",
    "    return np.array(hit_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_tokens(sess_tokens):\n",
    "    prev=set(sess_tokens[0].split(','))\n",
    "    lens=[]\n",
    "    for tokens in sess_tokens[1:]:\n",
    "        curr=set(tokens.split(','))\n",
    "        lens.append(len(prev&curr))\n",
    "        prev=curr\n",
    "    return lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df=pd.read_csv(f'./csvs/wandb_export_val_diginetica_32_{global_run_id}.csv')\n",
    "#runs_df=pd.read_csv('./csvs/wandb_export_nonspecial_32.csv')\n",
    "runs_df['cluster']=runs_df.Name.map(lambda x: int(x.split('_')[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_metrics(model, dataloader):\n",
    "    hit,mrr=[],[]\n",
    "\n",
    "    model.to('cuda')\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch=[b.to('cuda') for b in batch]\n",
    "\n",
    "        sub_scores, targets=model.predict_step(batch)\n",
    "        targets=targets.flatten()\n",
    "        for score, target in zip(sub_scores, targets):\n",
    "            correct_pred=torch.isin(target - 1, score).cpu()\n",
    "            hit.append(correct_pred)\n",
    "            if not correct_pred:\n",
    "                mrr.append(0)\n",
    "            else:\n",
    "                mrr.append(1 / (torch.where(score == target - 1)[0][0] + 1).cpu())\n",
    "\n",
    "    hit=np.array(hit)\n",
    "    mrr=np.array(mrr)\n",
    "    return {'cluster_hit': 100*np.average(hit), 'cluster_mrr': 100*np.average(mrr)}, hit, mrr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=[]\n",
    "cluster_results.append(\n",
    "{'cluster':-1, \n",
    " 'cluster_hit': np.average(hit),\n",
    " 'cluster_mrr': np.average(mrr)})\n",
    "\n",
    "cluster_hit=np.zeros_like(hit)\n",
    "cluster_mrr=np.zeros_like(mrr)\n",
    "\n",
    "for c in trange(gm.n_components):\n",
    "    clear_output(wait=True)\n",
    "    if runs_df.loc[runs_df.cluster==c].empty or not (session_labels==c).any():\n",
    "        continue\n",
    "    idxs=np.arange(len(test_data[0]))[session_labels==c]\n",
    "\n",
    "    cluster_sess=[test_data[0][i] for i in idxs]\n",
    "    cluster_targets=[test_data[1][i] for i in idxs]\n",
    "    cluster_data=(cluster_sess,cluster_targets)\n",
    "    cluster_dataset=SRGNN_Map_Dataset(cluster_data, shuffle=False)\n",
    "    cluster_dataloader=DataLoader(cluster_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(cluster_dataset, opt.batchSize, shuffle=False, drop_last=False),\n",
    "                             drop_last=False\n",
    "                            )\n",
    "    run_id=runs_df.loc[runs_df.cluster==c].ID.item()\n",
    "    cluster_model=SRGNN_model.load_from_checkpoint(f\"./GNN_master/{run_id}/checkpoints/\"+\n",
    "                                       os.listdir(f\"./GNN_master/{run_id}/checkpoints/\")[0], opt=opt)\n",
    "    \n",
    "    #trainer=pl.Trainer(limit_test_batches=ceil(cluster_dataset.length/opt.batchSize),limit_predict_batches=ceil(cluster_dataset.length/opt.batchSize))\n",
    "    #metrics=trainer.test(cluster_model, cluster_dataloader)[0]#only one dataloader\n",
    "    metrics, cluster_hits, cluster_mrrs=manual_metrics(cluster_model, cluster_dataloader)\n",
    "    cluster_hit[idxs]=cluster_hits\n",
    "    cluster_mrr[idxs]=cluster_mrrs\n",
    "    \n",
    "    metrics['cluster']=c\n",
    "    metrics['global_model_hit']=100*np.average(hit[idxs])\n",
    "    metrics['global_model_mrr']=100*np.average(mrr[idxs])\n",
    "    cluster_results.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=pd.DataFrame(cluster_results)\n",
    "cluster_results=cluster_results.merge(pd.DataFrame(np.unique(session_labels, return_counts=True)).T.rename(columns={0:'cluster',1:'cluster_size'}),\n",
    "                      on='cluster')\n",
    "cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cluster_results.cluster_hit>cluster_results.global_model_hit).any(), (cluster_results.cluster_mrr>cluster_results.global_model_mrr).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.iloc[np.arange(cluster_results.shape[0])[cluster_results.cluster_mrr>cluster_results.global_model_mrr]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.iloc[np.arange(cluster_results.shape[0])[cluster_results.cluster_hit>cluster_results.global_model_hit]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.loc[cluster_results.global_model_hit<np.average(hit)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=cluster_results.loc[\n",
    "    (cluster_results.global_model_hit<np.average(hit)*100)\n",
    "    #(~cluster_results.cluster.isin([4,31, 18, 0]))\n",
    "    &(cluster_results.cluster_size<5000)\n",
    "    ]\n",
    "df[['cluster', 'cluster_hit', 'global_model_hit',\n",
    "       'cluster_mrr', 'global_model_mrr',\n",
    "       'cluster_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h,m,s in zip((df.cluster_mrr-df.global_model_mrr).round(2).values, \n",
    "                 (df.cluster_hit-df.global_model_hit).round(2).values, \n",
    "                 df.cluster_size.values):\n",
    "    print(h, '&', m, '&', s, '\\\\\\\\ \\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.cluster_mrr-df.global_model_mrr).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.cluster_size).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### total gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop clusters that did overfit\n",
    "bad_clusters=df.cluster.values\n",
    "idxs=(np.logical_and(session_labels!=4, session_labels!=31))\n",
    "idxs2=False\n",
    "for i in [session_labels==c for c in bad_clusters]:\n",
    "    idxs2=np.logical_or(idxs2, i)\n",
    "idxs=np.logical_and(idxs, idxs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(hit[idxs]), np.mean(cluster_hit[idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mrr[idxs]), np.mean(cluster_mrr[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investigate on sessions types in each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diginetica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df=pd.read_csv('../datasets/diginetica/items.csv').drop(columns='Unnamed: 0')\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df=pd.read_csv('../datasets/diginetica/test_sessions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sessions, test_targets, test_sids=test_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df.loc[session_df.session_id==289]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "session_len=[]\n",
    "session_frequency=[]\n",
    "session_price=[]\n",
    "session_ctokens=[]\n",
    "session_categories=[]\n",
    "target_category=[]\n",
    "session_query=[]\n",
    "\n",
    "for idx, sid in tqdm(zip(range(len(test_sessions)), test_sids)):\n",
    "    sess_items_df=items_df.loc[items_df.item_number.isin(test_sessions[idx])].sort_values(by='item_number', \n",
    "                                                                                          key=np.vectorize(lambda x: test_sessions[idx].index(x)))\n",
    "    session_len.append(len(test_sessions[idx]))\n",
    "    session_frequency.append(np.average(sess_items_df.frequency))\n",
    "    session_price.append(np.average(sess_items_df.pricelog2))\n",
    "    session_ctokens.append(np.average(consecutive_tokens(sess_items_df['product.name.tokens'].values)))\n",
    "    session_categories.append(sess_items_df.category.nunique())\n",
    "\n",
    "    sess_target_categories=items_df.loc[items_df.item_number==test_targets[idx]].category\n",
    "    target_category.append(any([c in sess_items_df.category.values for c in sess_target_categories]))\n",
    "    session_query.append(session_df.loc[session])\n",
    "\n",
    "session_len=np.array(session_len)\n",
    "session_frequency=np.array(session_frequency)\n",
    "session_price=np.array(session_price)\n",
    "session_ctokens=np.array(session_ctokens)\n",
    "session_categories=np.array(session_categories)\n",
    "target_category=np.array(target_category)\n",
    "\n",
    "res.append((-1,\n",
    "            np.average(session_len),\n",
    "            np.median(session_len),\n",
    "            np.average(session_frequency),\n",
    "            np.median(session_frequency),\n",
    "            np.average(session_price),\n",
    "            np.median(session_price),\n",
    "            np.nanmean(session_ctokens),\n",
    "            np.nanmedian(session_ctokens),\n",
    "            np.average(session_categories),\n",
    "            np.median(session_categories),\n",
    "            np.average(target_category),\n",
    "            np.median(target_category)\n",
    "            ))\n",
    "\n",
    "\n",
    "for cluster in tqdm(cluster_results.cluster.unique()):\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "\n",
    "    res.append((cluster,\n",
    "                np.average(session_len[idxs]),\n",
    "                np.median(session_len[idxs]),\n",
    "                np.average(session_frequency[idxs]),\n",
    "                np.median(session_frequency[idxs]),\n",
    "                np.average(session_price[idxs]),\n",
    "                np.median(session_price[idxs]),\n",
    "                np.nanmean(session_ctokens[idxs]),\n",
    "                np.nanmedian(session_ctokens[idxs]),\n",
    "                np.average(session_categories[idxs]),\n",
    "                np.median(session_categories[idxs]),\n",
    "                np.average(target_category[idxs]),\n",
    "                np.median(target_category[idxs])\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(session_ctokens[~np.isnan(session_ctokens)], bins=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=cluster_results.merge(pd.DataFrame(res, columns=['cluster',\n",
    "                                             'avg_len', \n",
    "                                             'med_len', \n",
    "                                             'avg_freq',\n",
    "                                             'med_freq',\n",
    "                                             'avg_price',\n",
    "                                             'med_price',\n",
    "                                             'avg_ctokens',\n",
    "                                             'med_ctokens',\n",
    "                                             'avg_cats',\n",
    "                                             'med_cats',\n",
    "                                             'avg_target_cat',\n",
    "                                             'med_target_cat']), on='cluster').dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hit ratio & mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl=get_hit_ratio_per_len(lim=max_len)\n",
    "plt.bar(np.arange(1, max_len+1), gl, label='hit', bottom=0)\n",
    "plt.bar(np.arange(1, max_len+1), 1-gl, label='miss', bottom=gl)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=[('avg_len', \n",
    "'med_len', ),\n",
    "('avg_freq',\n",
    "'med_freq',),\n",
    "('avg_price',\n",
    "'med_price',),\n",
    "('avg_ctokens',\n",
    "'med_ctokens',),\n",
    "('avg_cats',\n",
    "'med_cats',),\n",
    "('avg_target_cat',\n",
    "'med_target_cat')]\n",
    "\n",
    "fig, ax=plt.subplots(len(cols), 2, sharex='col', sharey='row', figsize=(8, len(cols)*3), dpi=80)\n",
    "for i, (a,b) in enumerate(cols):\n",
    "    ax[i,0].set_title(a[4:])\n",
    "\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[a], label='avg')\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,0].grid()\n",
    "    ax[i,0].legend()\n",
    "\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[a], label='avg')\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,1].grid()\n",
    "    ax[i,1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.loc[cluster_results.avg_ctokens>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### hit&mrr X session length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterXlenXhit=[]\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=session_labels==cluster\n",
    "    lenghts=np.unique(session_len[idxs])\n",
    "    for l in lenghts:\n",
    "        if l >= max_len:\n",
    "            l_idxs=np.logical_and(session_labels==cluster, session_len>=l)\n",
    "            clusterXlenXhit.append((cluster, l, np.average(hit[l_idxs])))\n",
    "            break\n",
    "            \n",
    "        l_idxs=np.logical_and(session_labels==cluster, session_len==l)\n",
    "        clusterXlenXhit.append((cluster, l, np.average(hit[l_idxs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16, 12), dpi=80)\n",
    "\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    plt.plot([x[1] for x in clusterXlenXhit if x[0]==cluster], [x[2] for x in clusterXlenXhit if x[0]==cluster], label=cluster)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterXlenXmrr=[]\n",
    "max_len=10\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=session_labels==cluster\n",
    "    lenghts=np.unique(session_len[idxs])\n",
    "    for l in lenghts:\n",
    "        if l >= max_len:\n",
    "            l_idxs=np.logical_and(session_labels==cluster, session_len>=l)\n",
    "            clusterXlenXmrr.append((cluster, l, np.average(mrr[l_idxs])))\n",
    "            break\n",
    "            \n",
    "        l_idxs=np.logical_and(session_labels==cluster, session_len==l)\n",
    "        clusterXlenXmrr.append((cluster, l, np.average(mrr[l_idxs])))\n",
    "\n",
    "\n",
    "figure(figsize=(16, 12), dpi=80)\n",
    "\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    plt.plot([x[1] for x in clusterXlenXmrr if x[0]==cluster], [x[2] for x in clusterXlenXmrr if x[0]==cluster], label=cluster)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('clusterXlenXmrr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16, 12), dpi=80)\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "    clens, csizes=get_lenght_distribution(session_len[idxs], lim=max_len)\n",
    "    plt.plot(clens, csizes, label=cluster)\n",
    "\n",
    "clens, csizes=get_lenght_distribution(session_len, lim=max_len)\n",
    "plt.plot(clens, csizes, label='global', linewidth=3, linestyle='--', color='black')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yoochoose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "for k in trange(33003945//int(1e6)):\n",
    "    df=pd.read_table('../datasets/yoochoose-clicks.dat', sep=',', dtype=str,\n",
    "                     nrows=int(1e6), skiprows=k*int(1e6),\n",
    "                     names=['session_id','timestamp','item_id','category'])\n",
    "    df=df[['item_id', 'category']].drop_duplicates()\n",
    "    dfs.append(df)\n",
    "\n",
    "items_df=pd.concat(dfs).drop_duplicates()\n",
    "items_df=items_df.iloc[1:].reset_index(drop=True)\n",
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df=items_df.merge(pd.DataFrame(pickle.load(\n",
    "   # open('../datasets/yoochoose_itemdict_nonspecial.txt', 'rb')),\n",
    "    open('../datasets/yoochoose_itemdict_custom.txt', 'rb')),\n",
    "                                      index=[0]).T.reset_index().rename(columns={'index':'item_id', 0:'item_number'}),\n",
    "             on='item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items_df=items_df.loc[items_df.category.isin([str(c) for c in np.arange(1,13)])]\n",
    "\n",
    "with open('../datasets/yoochoose_custom/yoo_df.txt', 'rb') as f:\n",
    "    yoo_df=pickle.load(f)\n",
    "    freq_df=pd.DataFrame(np.asarray(np.unique(yoo_df.item_id, return_counts=True)).T, columns=['item_id','frequency'])\n",
    "\n",
    "    items_df=items_df.merge(freq_df, on='item_id')\n",
    "    del yoo_df\n",
    "    del freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sessions=[]\n",
    "test_targets=[]\n",
    "for batch in test_dataloader:\n",
    "    sess=batch[2].squeeze().detach()\n",
    "    for s in sess:\n",
    "        test_sessions.append(s[s>0].tolist())\n",
    "   # test_sessions.extend(sess[sess>0].tolist())\n",
    "    test_targets.extend(batch[4].squeeze().detach().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "def get_session_stats(idx, lock):\n",
    "    sess_items_df=items_df.loc[items_df.item_number.isin(test_sessions[idx])]\n",
    "    l=len(test_sessions[idx])\n",
    "    cat=sess_items_df.category.nunique()\n",
    "    sess_target_categories=items_df.loc[items_df.item_number==test_targets[idx]].category\n",
    "    tcat=any([c in sess_items_df.category.values for c in sess_target_categories])\n",
    "    clust=session_labels[idx]\n",
    "    sess_freq=np.average(sess_items_df.frequency)\n",
    "    with lock:\n",
    "        session_clusters.append(clust)\n",
    "        session_len.append(l)\n",
    "        session_frequency.append(sess_freq)\n",
    "        session_categories.append(cat)\n",
    "\n",
    "        target_category.append(tcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_len=[]\n",
    "session_frequency=[]\n",
    "session_categories=[]\n",
    "session_clusters=[]\n",
    "target_category=[]\n",
    "\n",
    "threads=[]\n",
    "lock=threading.Lock()\n",
    "try:\n",
    "    for idx in trange(len(test_sessions)):\n",
    "        thread=threading.Thread(target=get_session_stats, args=(idx, lock))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "except KeyboardInterrupt:\n",
    "    print('User interrupt')\n",
    "for thread in threads:\n",
    "    thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_len=np.array(session_len)\n",
    "#session_frequency=np.array(session_frequency)\n",
    "session_categories=np.array(session_categories)\n",
    "target_category=np.array(target_category)\n",
    "\n",
    "res=[]\n",
    "res.append((-1,\n",
    "            np.average(session_len),\n",
    "            np.median(session_len),\n",
    " #           np.average(session_frequency),\n",
    "  #          np.median(session_frequency),\n",
    "            np.average(session_categories),\n",
    "            np.median(session_categories),\n",
    "            np.average(target_category),\n",
    "            np.median(target_category)\n",
    "            ))\n",
    "\n",
    "\n",
    "for cluster in tqdm(cluster_results.cluster.unique()):\n",
    "    idxs=np.arange(session_labels.shape[0])[target_category==cluster]\n",
    "\n",
    "    res.append((cluster,\n",
    "                np.average(session_len[idxs]),\n",
    "                np.median(session_len[idxs]),\n",
    "    #            np.average(session_frequency[idxs]),\n",
    "   #             np.median(session_frequency[idxs]),\n",
    "                np.average(session_categories[idxs]),\n",
    "                np.median(session_categories[idxs]),\n",
    "                np.average(target_category[idxs]),\n",
    "                np.median(target_category[idxs])\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=[]\n",
    "session_len=[]\n",
    "session_frequency=[]\n",
    "session_categories=[]\n",
    "target_category=[]\n",
    "for idx in tqdm(range(len(test_sessions))):\n",
    "    sess_items_df=items_df.loc[items_df.item_number.isin(test_sessions[idx])]\n",
    "    session_len.append(len(test_sessions[idx]))\n",
    "    session_frequency.append(np.average(sess_items_df.frequency))\n",
    "    session_categories.append(sess_items_df.category.nunique())\n",
    "\n",
    "    sess_target_categories=items_df.loc[items_df.item_number==test_targets[idx]].category\n",
    "    target_category.append(any([c in sess_items_df.category.values for c in sess_target_categories]))\n",
    "\n",
    "session_len=np.array(session_len)\n",
    "session_frequency=np.array(session_frequency)\n",
    "session_categories=np.array(session_categories)\n",
    "target_category=np.array(target_category)\n",
    "\n",
    "res.append((-1,\n",
    "            np.average(session_len),\n",
    "            np.median(session_len),\n",
    "            np.average(session_frequency),\n",
    "            np.median(session_frequency),\n",
    "            np.average(session_categories),\n",
    "            np.median(session_categories),\n",
    "            np.average(target_category),\n",
    "            np.median(target_category)\n",
    "            ))\n",
    "\n",
    "\n",
    "for cluster in tqdm(cluster_results.cluster.unique()):\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "\n",
    "    res.append((cluster,\n",
    "                np.average(session_len[idxs]),\n",
    "                np.median(session_len[idxs]),\n",
    "                np.average(session_frequency[idxs]),\n",
    "                np.median(session_frequency[idxs]),\n",
    "                np.average(session_categories[idxs]),\n",
    "                np.median(session_categories[idxs]),\n",
    "                np.average(target_category[idxs]),\n",
    "                np.median(target_category[idxs])\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results=cluster_results.merge(pd.DataFrame(res, columns=['cluster',\n",
    "                                             'avg_len', \n",
    "                                             'med_len', \n",
    "                                             'avg_freq',\n",
    "                                             'med_freq',\n",
    "                                             'avg_cats',\n",
    "                                             'med_cats',\n",
    "                                             'avg_target_cat',\n",
    "                                             'med_target_cat']), on='cluster').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols=[('avg_len', \n",
    "'med_len', ),\n",
    "('avg_freq',\n",
    "'med_freq',),\n",
    "('avg_cats',\n",
    "'med_cats',),\n",
    "('avg_target_cat',\n",
    "'med_target_cat')]\n",
    "\n",
    "fig, ax=plt.subplots(4, 2, sharex='col', sharey='row', figsize=(8, 12), dpi=80)\n",
    "for i, (a,b) in enumerate(cols):\n",
    "    ax[i,0].set_title(a[4:])\n",
    "\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[a], label='avg')\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,0].grid()\n",
    "    ax[i,0].legend()\n",
    "\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[a], label='avg')\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,1].grid()\n",
    "    ax[i,1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NONSPECIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[('avg_len', \n",
    "'med_len', ),\n",
    "('avg_freq',\n",
    "'med_freq',),\n",
    "('avg_cats',\n",
    "'med_cats',),\n",
    "('avg_target_cat',\n",
    "'med_target_cat')]\n",
    "\n",
    "fig, ax=plt.subplots(4, 2, sharex='col', sharey='row', figsize=(8, 12), dpi=80)\n",
    "for i, (a,b) in enumerate(cols):\n",
    "    ax[i,0].set_title(a[4:])\n",
    "\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[a], label='avg')\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,0].grid()\n",
    "    ax[i,0].legend()\n",
    "\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[a], label='avg')\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,1].grid()\n",
    "    ax[i,1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GM&TSNE scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne=TSNE(2)\n",
    "tsne_session_embeddings=tsne.fit_transform(session_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for label in np.unique(session_labels):\n",
    "    label_embedding=tsne_session_embeddings[session_labels==label]\n",
    "    fig.add_trace(go.Scatter(x=label_embedding[:,0], y=label_embedding[:,1], name=str(label), mode='markers'))\n",
    "\n",
    "fig.update_layout(title='TSNE reduced session embeddings with GM',\n",
    "                  margin=dict(l=40, r=40, t=40, b=40),\n",
    "                  width=1000, height=800)\n",
    "fig.write_html(f'./images/test_sessions_ontrain_{opt.dataset}_{opt.hiddenSize}.html')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32 clusters, GM trained on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[('avg_len', \n",
    "'med_len', ),\n",
    "('avg_freq',\n",
    "'med_freq',),\n",
    "('avg_cats',\n",
    "'med_cats',),\n",
    "('avg_target_cat',\n",
    "'med_target_cat')]\n",
    "\n",
    "fig, ax=plt.subplots(4, 2, sharex='col', sharey='row', figsize=(8, 12), dpi=80)\n",
    "for i, (a,b) in enumerate(cols):\n",
    "    ax[i,0].set_title(a[4:])\n",
    "\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[a], label='avg')\n",
    "    ax[i,0].scatter(cluster_results.test_hit, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,0].grid()\n",
    "    ax[i,0].legend()\n",
    "\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[a], label='avg')\n",
    "    ax[i,1].scatter(cluster_results.test_mrr, cluster_results[b], label='med', alpha=0.7)\n",
    "    ax[i,1].grid()\n",
    "    ax[i,1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyse session lengths in a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterXlenXhit=[]\n",
    "max_len=10\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=session_labels==cluster\n",
    "    lenghts=np.unique(session_len[idxs])\n",
    "    for l in lenghts:\n",
    "        if l >= max_len:\n",
    "            l_idxs=np.logical_and(session_labels==cluster, session_len>=l)\n",
    "            clusterXlenXhit.append((cluster, l, np.average(hit[l_idxs])))\n",
    "            break\n",
    "            \n",
    "        l_idxs=np.logical_and(session_labels==cluster, session_len==l)\n",
    "        clusterXlenXhit.append((cluster, l, np.average(hit[l_idxs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results.loc[cluster_results.test_hit<40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16, 12), dpi=80)\n",
    "\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    plt.plot([x[1] for x in clusterXlenXhit if x[0]==cluster], [x[2] for x in clusterXlenXhit if x[0]==cluster], label=cluster)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterXlenXmrr=[]\n",
    "max_len=10\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=session_labels==cluster\n",
    "    lenghts=np.unique(session_len[idxs])\n",
    "    for l in lenghts:\n",
    "        if l >= max_len:\n",
    "            l_idxs=np.logical_and(session_labels==cluster, session_len>=l)\n",
    "            clusterXlenXmrr.append((cluster, l, np.average(mrr[l_idxs])))\n",
    "            break\n",
    "            \n",
    "        l_idxs=np.logical_and(session_labels==cluster, session_len==l)\n",
    "        clusterXlenXmrr.append((cluster, l, np.average(mrr[l_idxs])))\n",
    "\n",
    "\n",
    "figure(figsize=(16, 12), dpi=80)\n",
    "\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    plt.plot([x[1] for x in clusterXlenXmrr if x[0]==cluster], [x[2] for x in clusterXlenXmrr if x[0]==cluster], label=cluster)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.title('clusterXlenXmrr')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl=get_hit_ratio_per_len(lim=max_len)\n",
    "plt.bar(np.arange(1, max_len+1), gl, label='hit', bottom=0)\n",
    "plt.bar(np.arange(1, max_len+1), 1-gl, label='miss', bottom=gl)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(16, 12), dpi=80)\n",
    "for cluster in cluster_results.cluster.unique():\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "    clens, csizes=get_lenght_distribution(session_len[idxs], lim=max_len)\n",
    "    plt.plot(clens, csizes, label=cluster)\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glens, gsizes=get_lenght_distribution(session_len)\n",
    "\n",
    "for cluster in cluster_results.iloc[np.arange(cluster_results.shape[0])[cluster_results.test_hit>cluster_results.global_model_hit]].cluster:\n",
    "#for cluster in cluster_results.cluster.unique():\n",
    "    idxs=np.arange(session_labels.shape[0])[session_labels==cluster]\n",
    "    clens, csizes=get_lenght_distribution(session_len[idxs])\n",
    "\n",
    "    plt.bar(clens, csizes, label='cluster')\n",
    "    plt.bar(clens, gsizes[:len(clens)]-csizes, label='diff from global', alpha=0.5)\n",
    "    plt.grid()\n",
    "    plt.xlabel('session length')\n",
    "    plt.xticks(np.arange(len(clens)+1))\n",
    "    plt.legend()\n",
    "    plt.title(f'''cluster {cluster}, size {cluster_results.loc[cluster_results.cluster==cluster]['size'].item()}, \n",
    "              max diff={max(np.abs(gsizes[:len(clens)]-csizes)):.4f}, \n",
    "              total diff={sum(np.abs(gsizes[:len(clens)]-csizes)):.4f},\n",
    "              hit={cluster_results.loc[cluster_results.cluster==cluster].test_hit.item():.2f}\n",
    "              global_hit={cluster_results.loc[cluster_results.cluster==cluster].global_model_hit.item():.2f}\n",
    "''')\n",
    "    plt.show()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
