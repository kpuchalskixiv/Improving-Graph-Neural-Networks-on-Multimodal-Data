{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from srgnn_datasets import SRGNN_Map_Dataset, Augment_Matrix_Dataset, SRGNN_sampler, Clusters_Matrix_Dataset\n",
    "from utils import load_model, get_dataset, load_model_gm\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_by_hand(model, dataloaders):\n",
    "    m=[]\n",
    "    for i, d in enumerate(dataloaders):\n",
    "        hit,mrr=[],[]\n",
    "        for batch in tqdm(d, total=ceil(normal_test_dataset.length/opt.batchSize)):\n",
    "            batch=[x.to('cuda') for x in batch]\n",
    "            sub_scores, targets=model.predict_step(batch)\n",
    "            targets=targets.flatten()\n",
    "            for score, target in zip(sub_scores, targets):\n",
    "                correct_pred=torch.isin(target - 1, score)\n",
    "                hit.append(correct_pred.cpu().numpy())\n",
    "                if not correct_pred:\n",
    "                    mrr.append(0)\n",
    "                else:\n",
    "                    mrr.append(1 / (torch.where(score == target - 1)[0][0] + 1).cpu().numpy())\n",
    "        m.append((i, 100*np.average(hit),100*np.average(mrr)))\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# otto-recsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['7dt7uu2i', '31mccq76', 'f42h3b7i', 'z5gthlar', 'icirdid1',\n",
    "    'q5ncdos3',\n",
    " '20x2q8ap',\n",
    " 'edk5gwaj',\n",
    " 'eyipcpfr',\n",
    " 'u1769vwh',\n",
    " '7toa2ybx',\n",
    " 'zrkfqp80',\n",
    " '0dqi0cx4',\n",
    " 'leop64a1',\n",
    " 'c4l0cw03',\n",
    " 'rufekv8o',\n",
    " 'zja7utqy',\n",
    " 'lc8hf28y',\n",
    " 'pi1q0ni6',\n",
    " '78wwq4e4',\n",
    "\n",
    "'7oziz2pv',\n",
    "'77r7ocil',\n",
    "'umy0p2nx',\n",
    "'ch778pru',\n",
    "'dn0mhesi',\n",
    "'qpljbobb',\n",
    "'s8wy4wxs',\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=runs[0]\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )\n",
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_noise_p','augment_alg']].groupby(['augment_matrix', 'augment_noise_p', 'augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yoochoose 1/64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id='7zi9x9w8'\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    '7zi9x9w8'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    print('Metrics on normal Adjacency matrix')\n",
    "    print(run_id)\n",
    "    trainer.test(model, normal_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmented models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[ # yoochoose1/64\n",
    "    'qgkxyze7',\n",
    "    'r1xr7g4v',\n",
    "    'itxri54t',\n",
    "    '7vvqd0ib',\n",
    "    'jefoas5f',\n",
    "    'ai6ytfw2',\n",
    "    'xm3z645m',\n",
    "    'zf87zj40',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    print('Distnace Augmentation:', opt.augment_matrix,\n",
    "        'Clusters:', opt.augment_clusters,\n",
    "          'Categories:', opt.augment_categories,\n",
    "          'Noise std: ', opt.augment_std,\n",
    "          'base model', opt.augment_old_run_id,\n",
    "          )\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    metrics['augment_nogmm']=opt.augment_nogmm\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)\n",
    "res_df.drop(columns='run_id').groupby('augment_nogmm').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    #dataset=get_dataset(opt)\n",
    "   # am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "     #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "      #                   )\n",
    "    print(run_id)\n",
    "    print('Distnace Augmentation:', opt.augment_matrix,\n",
    "        'Clusters:', opt.augment_clusters,\n",
    "          'Categories:', opt.augment_categories,\n",
    "          'Noise std: ', opt.augment_std,\n",
    "          'base model', opt.augment_old_run_id,\n",
    "          )\n",
    "    results[run_id]=get_metrics_by_hand(model, [normal_test_dataloader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_res_df=pd.DataFrame(results).T.reset_index()\n",
    "manual_res_df[['DataLoader_id','hit','mrr']]=pd.DataFrame(manual_res_df[0].to_list(), columns=['DataLoader_id','hit','mrr'])\n",
    "manual_res_df.rename(columns={'index':'run_id'}, inplace=True)\n",
    "manual_res_df.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullres_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=res_df.merge(manual_res_df,  on='run_id')\n",
    "res_df.drop(columns='run_id').groupby('augment_nogmm').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=\"\"\"jcohtdpz\n",
    "c7lixdzn\n",
    "9r9e7dsx\n",
    "lx4jtu4g\n",
    "au07imlq\n",
    "u337t04h\n",
    "k7eoaxze\n",
    "ln32zyo6\n",
    "ud3mdfu3\n",
    "zw2j8lcv\n",
    "k598voxs\n",
    "r5p9ms90\n",
    "qhcln02h\n",
    "1ttxe7ox\n",
    "cqw7xz4i\n",
    "gd66gitx\n",
    "alh21te8\n",
    "da4ptrb0\n",
    "khflo2wo\n",
    "uyyjj6l8\n",
    "554tdh98\n",
    "eoart48b\n",
    "had1602b\n",
    "0d2jc7tz\n",
    "8r761av3\n",
    "svgb60go\n",
    "4627kuot\n",
    "ye95z6m4\"\"\".split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['ahsuiwog', 'e8j91dlm', 'sn0yz16r', 'zhy3fnyf', 'c31yywda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise only\n",
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_alg']].groupby(['augment_matrix','augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_alg']].groupby(['augment_matrix','augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yoochoose 1/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=\"\"\"3j5nkw4m\n",
    "fxrwajhe\n",
    "vmbjvdhs\n",
    "6vpf6swz\n",
    "hbuhmnxw\n",
    "za9sjn76\n",
    "bchj1eho\"\"\".split('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_alg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_alg']].groupby(['augment_matrix','augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diginetica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id='qm2ur7o3'\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[ ## default hparams, as in paper\n",
    "    'run-20240916_203347-izcd5fci',\n",
    "    'run-20240916_200756-q3fjvapa',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    ## my hparams\n",
    "    'qm2ur7o3',\n",
    "    '3abge2uq',\n",
    "    '4dm99qnd',\n",
    "    'jxgwsuta',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    model,opt=load_model(run_id)\n",
    "    print('Metrics on normal Adjacency matrix')\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, normal_test_dataloader)[0]\n",
    "    metrics['run_id']=run_id\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res_df)[['test_loss','test_hit','test_mrr']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['s4uxxqad', 'rbwxpsy6', 'ba46mnkl', 'h2a8ujnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)\n",
    "res_df=pd.DataFrame(res_df)\n",
    "res_df.groupby('augment_matrix')[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmented models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[ \n",
    "    '9kf534bm',\n",
    "    'nbhakjb7',\n",
    "    'fmm07us9',\n",
    "    'wtqp9kti',\n",
    "    'dlnjkkym',\n",
    "    'rrqcjbjh',\n",
    "    '4kxamho0',\n",
    "    'cx8cnx7m',    \n",
    "    'seb1ybp1',    \n",
    "    'bgqjpxh8',    \n",
    "    'r8d4fcqv',    \n",
    "    'ey3bjtz5',    \n",
    "    '8npur3kf',  \n",
    "    '21wtiveg',\n",
    "    'run-20240916_191647-vyrrq40z',\n",
    "    'run-20240916_185628-j8kqiv89',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20240916_191647-vyrrq40z',\n",
    "    'run-20240916_185628-j8kqiv89',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4 times per each # gmms\n",
    "runs=['yp1n5fb3', 'naj1qrsy', 'pl1wvihn', 's7r181i0', 'fp4lprkj',\n",
    "       'yrq35hmp', 'pxgponas', '31hc2s4t', 'v94f9jmw', '9wa54kna',\n",
    "       'xbpg8ncx', 'kltkp2te', 'z7mdp78e', 'o9t9gt9v', 'qdxqwnrw',\n",
    "       '0zl3ui7x', '7jkmaij6', 'ud4ap40l', '5k1ezsql', 'zkgt4s6x',\n",
    "       'egqyw7yg', '6ixyzjk9', 'ub1h5qr3', '8iea3bxp', '8f9v8z85',\n",
    "       'f80nrp4r', 'b60x4mtc', 'm8n6p80h', '26kyds0s', '628jlwv2',\n",
    "       'dwgw5a3v', '18j6ce86', 'b5pfaja0', 'rwhslx2m', 'gt0rzzmz',\n",
    "       'xscwi8xw', 'kkpuxgtn']+['c7pzwt2z', '17uejl8y', '57zrr3vh', 'op22qkq4']+['uxt9w9tv', '1qly30ga', 'y7yqfh84', '6i71w436']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=[\n",
    "    'run-20241002_162623-kkpuxgtn',\n",
    "    'run-20241002_160557-9ueod1xy',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby(['augment_nogmm','augment_old_run_id'])[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby(['augment_alg','augment_nogmm'])[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.loc[res_df.augment_nogmm==8][['test_loss', 'test_hit', 'test_mrr','augment_alg', 'augment_old_run_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for run_id in runs:\n",
    "  try:\n",
    "    model,opt=load_model(run_id)\n",
    "  except IndexError:\n",
    "      continue    #dataset=get_dataset(opt)\n",
    "  # am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "  #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "  #                   )\n",
    "  print(run_id)\n",
    "  print('Distnace Augmentation:', opt.augment_matrix,\n",
    "      'Clusters:', opt.augment_clusters,\n",
    "        'Categories:', opt.augment_categories,\n",
    "        'Noise std: ', opt.augment_std,\n",
    "        'base model', opt.augment_old_run_id,\n",
    "        )\n",
    "  metrics=get_metrics_by_hand(model, [normal_test_dataloader])\n",
    "  results[run_id]=metrics\n",
    "  print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_res_df=pd.DataFrame(results).T.reset_index()\n",
    "manual_res_df[['DataLoader_id','hit','mrr']]=pd.DataFrame(manual_res_df[0].to_list(), columns=['DataLoader_id','hit','mrr'])\n",
    "manual_res_df.rename(columns={'index':'run_id'}, inplace=True)\n",
    "manual_res_df.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=res_df.merge(manual_res_df,  on='run_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby('augment_nogmm')[['test_loss', 'test_hit', 'hit_x','test_mrr','mrr_x']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## categories runs for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['c7pzwt2z', '17uejl8y', '57zrr3vh', 'op22qkq4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby(['augment_nogmm'])[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i2i distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['yfd2pi3n', 'ss45a3b3', 'nwgcf1hh', '8llxhkxm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby(['augment_nogmm'])[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for run_id in runs:\n",
    "  try:\n",
    "    model,opt=load_model(run_id)\n",
    "  except IndexError:\n",
    "      continue    #dataset=get_dataset(opt)\n",
    "  # am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "  #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "  #                   )\n",
    "  print(run_id)\n",
    "  print('Distnace Augmentation:', opt.augment_matrix,\n",
    "      'Clusters:', opt.augment_clusters,\n",
    "        'Categories:', opt.augment_categories,\n",
    "        'Noise std: ', opt.augment_std,\n",
    "        'base model', opt.augment_old_run_id,\n",
    "        )\n",
    "  metrics=get_metrics_by_hand(model, [normal_test_dataloader])\n",
    "  results[run_id]=metrics\n",
    "  print(metrics)\n",
    "manual_res_df=pd.DataFrame(results).T.reset_index()\n",
    "manual_res_df[['DataLoader_id','hit','mrr']]=pd.DataFrame(manual_res_df[0].to_list(), columns=['DataLoader_id','hit','mrr'])\n",
    "manual_res_df.rename(columns={'index':'run_id'}, inplace=True)\n",
    "manual_res_df.drop(columns=0, inplace=True)\n",
    "res_df=res_df.merge(manual_res_df,  on='run_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby('augment_nogmm')[['test_loss', 'test_hit', 'hit','test_mrr','mrr']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i2i no normalization aug_p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['s2qhugqc', '1jvw1mc3', 'gpx6kyhh', 'vx4bvbxf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)\n",
    "res_df=pd.DataFrame(res_df)\n",
    "res_df.groupby('augment_matrix')[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i2i no normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['o6eky4nz', '0todhcp5', 'czhmlmnc', 'cc0e54iw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)\n",
    "res_df=pd.DataFrame(res_df)\n",
    "res_df.groupby('augment_matrix')[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kmeans augmented runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['uxt9w9tv', '1qly30ga', 'y7yqfh84', '6i71w436']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby(['augment_nogmm'])[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "for run_id in runs:\n",
    "  try:\n",
    "    model,opt=load_model(run_id)\n",
    "  except IndexError:\n",
    "      continue    #dataset=get_dataset(opt)\n",
    "  # am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "  #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "  #                   )\n",
    "  print(run_id)\n",
    "  print('Distnace Augmentation:', opt.augment_matrix,\n",
    "      'Clusters:', opt.augment_clusters,\n",
    "        'Categories:', opt.augment_categories,\n",
    "        'Noise std: ', opt.augment_std,\n",
    "        'base model', opt.augment_old_run_id,\n",
    "        )\n",
    "  metrics=get_metrics_by_hand(model, [normal_test_dataloader])\n",
    "  results[run_id]=metrics\n",
    "  print(metrics)\n",
    "manual_res_df=pd.DataFrame(results).T.reset_index()\n",
    "manual_res_df[['DataLoader_id','hit','mrr']]=pd.DataFrame(manual_res_df[0].to_list(), columns=['DataLoader_id','hit','mrr'])\n",
    "manual_res_df.rename(columns={'index':'run_id'}, inplace=True)\n",
    "manual_res_df.drop(columns=0, inplace=True)\n",
    "res_df=res_df.merge(manual_res_df,  on='run_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby('augment_nogmm')[['test_loss', 'test_hit', 'hit','test_mrr','mrr']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id='run-20240930_183501-kmnrqi6i'\n",
    "\n",
    "aug_run_ids=[\n",
    "    'run-20241002_140249-xros8ub6',\n",
    "    'run-20241002_131153-wijus07w',\n",
    "    'run-20241002_124004-pkv65nix',\n",
    "    'run-20241002_121528-v3ukvj2b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_run_id in [run_id]+aug_run_ids:\n",
    "    model,opt=load_model(test_run_id)\n",
    "\n",
    "    print(test_run_id, opt.augment_matrix, opt.augment_alg)\n",
    "    trainer.test(model, normal_test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augment + GM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['v9h49456', 'c7ihc3ll', 'jadnjsru', 'pbreuu0o']\n",
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model_gm(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)\n",
    "res_df=pd.DataFrame(res_df)\n",
    "res_df.groupby('augment_matrix')[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=['zq77vmnb','fpu7ucbf']+['12bdl9rw', 'wsix33ma', '1lh9waxz', 'nqk6cfps']+['n02c6569', 'q9w5okna', 'ltt7vsmv', '7o8vwuxv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model_gm(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "    #dataset=get_dataset(opt)\n",
    "    #am_test_dataloader=DataLoader(dataset,    num_workers=os.cpu_count(),  \n",
    "    #                       sampler=SRGNN_sampler(dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "    #                     )\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.groupby('augment_matrix')[['test_loss', 'test_hit', 'test_mrr',]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## otto-recsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['5f8cxkla', 'bqpaq7d1', 'onjpsmm2',\n",
    "        '14oq6k8n',\n",
    "  'uebl28zc',\n",
    "  'tfeek0n2',\n",
    "  '6u14u7kn',\n",
    "  'gcvf1rcu',\n",
    "  'ih8175d2',\n",
    "  'l2w97z5v',\n",
    "  '1uwq99zx',\n",
    "  '4l1c4ls3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=runs[0]\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )\n",
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_noise_p','augment_alg']].groupby(['augment_matrix', 'augment_noise_p', 'augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## yoochoose 1/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = [\n",
    " 'r7bs25i7',\n",
    " '2ssf7s2q',\n",
    " 'hucuxl8g',\n",
    " '1iwv7ul8',\n",
    " 'sqvv043i',\n",
    " '6hkj647n'   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=runs[0]\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "opt.batchSize=32\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )\n",
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_noise_p','augment_alg']].groupby(['augment_matrix', 'augment_noise_p', 'augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diginetica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = ['uasx1mwm', 'kig9t38y', 'i0o5vrfp', 'keifx1eb','w0dp5onn','paiznfvc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id=runs[0]\n",
    "\n",
    "model,opt=load_model(run_id)\n",
    "opt.batchSize=32\n",
    "test_data = pickle.load(open('../datasets/' + opt.dataset + '/test.txt', 'rb'))\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, opt.batchSize, shuffle=False, drop_last=False)\n",
    "                            )\n",
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/opt.batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/opt.batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=[]\n",
    "for run_id in runs:\n",
    "    try:\n",
    "      model,opt=load_model(run_id)\n",
    "    except IndexError:\n",
    "       continue\n",
    "\n",
    "    print(run_id)\n",
    "    metrics=trainer.test(model, {#'augmented':am_test_dataloader, \n",
    "                                 'normal':normal_test_dataloader})[0 ]\n",
    "    metrics['run_id']=run_id\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    res_df.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'run_id','augment_matrix','augment_alg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[['test_loss', 'test_hit', 'test_mrr', 'augment_matrix','augment_noise_p','augment_alg']].groupby(['augment_matrix', 'augment_noise_p', 'augment_alg']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
