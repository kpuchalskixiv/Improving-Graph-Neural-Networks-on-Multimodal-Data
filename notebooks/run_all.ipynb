{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_pl import main as train_model\n",
    "from main_gmgnn import main as train_model_gngmm\n",
    "from label_items_with_gmm import main as label_with_gmm\n",
    "from label_items_with_kmeans import main as label_with_kmeans\n",
    "from basic_cat_augmentation import main as label_with_categories\n",
    "from torch import set_float32_matmul_precision\n",
    "set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='diginetica'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_runs=[\n",
    "    ## my hparams, previosulsy calculated base runs\n",
    "    'qm2ur7o3',\n",
    "    '3abge2uq',\n",
    "    '4dm99qnd',\n",
    "    'jxgwsuta',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search for best # clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_common_flags=f\"--dataset {dataset} --augment-alg gmm --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-noise-p 0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "for rid in base_runs:\n",
    "    for no_gmm in [4, 8, 16, 32, 64, 128]:\n",
    "        extra_flags=f'--augment-old-run-id {rid} --augment-nogmm {no_gmm} '\n",
    "\n",
    "        gmm_label_flags=f\"--run-id {rid} --no-clusters {no_gmm}\"\n",
    "        label_with_gmm(gmm_label_flags.strip())\n",
    "\n",
    "        augmented_model_flags=augmented_common_flags+\" \"+extra_flags\n",
    "        aug_rid=train_model(\n",
    "            augmented_model_flags.strip()\n",
    "        )\n",
    "        augmented_run_ids.append(aug_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "\n",
    "augmented_common_flags=f\"--dataset {dataset} --augment-alg kmeans --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-noise-p 0.5\"\n",
    "for rid in base_runs:\n",
    "    extra_flags=f'--augment-old-run-id {rid} --augment-nogmm {8} '\n",
    "\n",
    "    gmm_label_flags=f\"--run-id {rid} --no-clusters {8}\"\n",
    "    label_with_kmeans(gmm_label_flags.strip())\n",
    "\n",
    "    augmented_model_flags=augmented_common_flags+\" \"+extra_flags\n",
    "    aug_rid=train_model(\n",
    "        augmented_model_flags.strip()\n",
    "    )\n",
    "    augmented_run_ids.append(aug_rid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "augmented_common_flags=f\"--dataset {dataset} --augment-alg categories --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-noise-p 0.5\"\n",
    "for rid in base_runs:\n",
    "    extra_flags=f'--augment-old-run-id {rid}'\n",
    "\n",
    "    gmm_label_flags=f\"--run-id {rid}\"\n",
    "    label_with_categories(gmm_label_flags.strip())\n",
    "\n",
    "    augmented_model_flags=augmented_common_flags+\" \"+extra_flags\n",
    "    aug_rid=train_model(\n",
    "        augmented_model_flags.strip()\n",
    "    )\n",
    "    augmented_run_ids.append(aug_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i2i distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "augmented_common_flags=f\"--augment-p 1 --dataset {dataset} --augment-alg raw --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --l2 0.000001 --augment-noise-p 0.5\"\n",
    "for rid in base_runs:\n",
    "    extra_flags=f'--augment-old-run-id {rid}'\n",
    "\n",
    "    augmented_model_flags=augmented_common_flags+\" \"+extra_flags\n",
    "    aug_rid=train_model(\n",
    "        augmented_model_flags.strip()\n",
    "    )\n",
    "    augmented_run_ids.append(aug_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "no_gmm=8\n",
    "augmented_common_flags=f\"--dataset {dataset} --augment-alg raw --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-noise-p 0.5\"\n",
    "\n",
    "for rid in base_runs:\n",
    "    extra_flags=f'--augment-old-run-id {rid} --augment-nogmm {no_gmm} '\n",
    "\n",
    "    gmm_label_flags=f\"--run-id {rid} --no-clusters {no_gmm}\"\n",
    "    \n",
    "    label_with_gmm(gmm_label_flags.strip())\n",
    "\n",
    "    augmented_model_flags=augmented_common_flags+\" \"+extra_flags\n",
    "    aug_rid=train_model_gngmm(\n",
    "        augmented_model_flags.strip()\n",
    "    )\n",
    "    augmented_run_ids.append(aug_rid)\n",
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base GM induced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_run_ids=[]\n",
    "no_gmm=8\n",
    "base_common_flags=f\"--dataset {dataset} --validation --valid-portion 0.1 --step 2 --lr-dc-step 3 --patience 5\"\n",
    "\n",
    "for rid in base_runs:\n",
    "    extra_flags=f'--augment-old-run-id {rid} --augment-nogmm {no_gmm} '\n",
    "\n",
    "\n",
    "    augmented_model_flags=base_common_flags+\" \"+extra_flags\n",
    "    aug_rid=train_model_gngmm(\n",
    "        augmented_model_flags.strip()\n",
    "    )\n",
    "    augmented_run_ids.append(aug_rid)\n",
    "augmented_run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_dist_flag=\"--augment-clusters\" #/'--augment-categories' or '' for i2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_str=f\"--dataset {dataset} --validation --valid-portion 0.1 --lr-scheduler step --step 2 --lr-dc-step 2 --patience 5\"\n",
    "rid=train_model(\n",
    "    flag_str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_gmm in [2, 8, 32, 128]:\n",
    "    if augment_dist_flag==\"--augment-clusters\":\n",
    "        gmm_label_flags=f\"--run-id {rid} --no-clusters {no_gmm}\"\n",
    "        label_with_gmm(gmm_label_flags.strip())\n",
    "\n",
    "    elif augment_dist_flag=='--augment-categories':\n",
    "        cat_label_flags=f\"--run-id {rid}\"\n",
    "        label_with_categories(cat_label_flags.strip())\n",
    "        \n",
    "    augmented_model_flags=f\"--dataset {dataset} --validation --valid-portion 0.1 --lr-scheduler step --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-old-run-id {rid} {augment_dist_flag} --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-nogmm {no_gmm} --augment-noise-p 0.5\"\n",
    "    for i in range(2):\n",
    "        _=train_model(\n",
    "            augmented_model_flags.strip()\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rerun baseline+augmented K times, compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from srgnn_datasets import SRGNN_Map_Dataset, SRGNN_sampler\n",
    "from utils import load_model\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from math import ceil\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='otto-recsys'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "\n",
    "base_run_ids=[]\n",
    "aug_run_ids=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## noise only\n",
    "for i in range(k):\n",
    "    flag_str=f\"--dataset {dataset} --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 5 --augment-noise-p 0.5 --augment-std 0.01\"\n",
    "    rid=train_model(\n",
    "        flag_str.strip()\n",
    "    )\n",
    "    base_run_ids.append(rid)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batchSize=256\n",
    "\n",
    "for i in range(k):\n",
    "    flag_str=f\"--dataset {dataset} --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 5\"\n",
    "    rid=train_model(\n",
    "        flag_str.strip()\n",
    "    )\n",
    "    base_run_ids.append(rid)\n",
    "\n",
    "    clustering_label_flags=f\"--run-id {rid} --no-clusters {8}\"\n",
    "    label_with_gmm(clustering_label_flags.strip())\n",
    "    label_with_kmeans(clustering_label_flags.strip())\n",
    "    if dataset!='otto-recsys':\n",
    "        label_with_categories(f\"--run-id {rid}\".strip())\n",
    "\n",
    "    augmented_common_flags=f\"--dataset {dataset} --augment-old-run-id {rid} --augment-nogmm 8 --validation --valid-portion 0.1 --step 2 --lr-dc-step 2 --patience 4 --augment-matrix --augment-std 0.01 --augment-normalize --augment-p 0.5 --l2 0.000001 --augment-noise-p 0.5\"\n",
    "\n",
    "    for alg in ['categories','gmm', 'kmeans', 'raw']:\n",
    "        if dataset=='otto-recsys' and alg=='categories':\n",
    "            continue\n",
    "        alg_flag=f\"--augment-alg {alg}\"\n",
    "        \n",
    "        augmented_model_flags=augmented_common_flags+\" \"+alg_flag\n",
    "        aug_rid=train_model(\n",
    "            augmented_model_flags.strip()\n",
    "        )\n",
    "        aug_run_ids.append(aug_rid)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_run_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/' + dataset + '/test.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "normal_test_dataset=SRGNN_Map_Dataset(test_data, shuffle=False)\n",
    "\n",
    "batchSize=100\n",
    "normal_test_dataloader=DataLoader(normal_test_dataset, \n",
    "                            num_workers=os.cpu_count(),  \n",
    "                            sampler=SRGNN_sampler(normal_test_dataset, batchSize, shuffle=False, drop_last=False)\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(limit_test_batches=ceil(normal_test_dataset.length/batchSize),\n",
    "                limit_predict_batches=ceil(normal_test_dataset.length/batchSize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_res_df=[]\n",
    "for run_id in base_run_ids:\n",
    "    model,opt=load_model(run_id)\n",
    "\n",
    "    metrics=trainer.test(model, {'normal':normal_test_dataloader})[0]\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    base_res_df.append(metrics)\n",
    "\n",
    "aug_res_df=[]\n",
    "for run_id in aug_run_ids:\n",
    "    model,opt=load_model(run_id)\n",
    "\n",
    "    metrics=trainer.test(model, {'normal':normal_test_dataloader})[0]\n",
    "    for k,v in opt.__dict__.items():\n",
    "       metrics[k]=v\n",
    "    aug_res_df.append(metrics)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df=pd.DataFrame(aug_res_df+base_res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv(f'./final_results/res_df_{\"_\".join(res_df.run_id.tolist())}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.drop(columns='run_id').groupby('augment_matrix').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
